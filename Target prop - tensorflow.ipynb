{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/jeff/Documents/Python/_projects/tdadl/')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from toy_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40152536, -0.26838267, -0.87564155],\n",
       "       [ 0.74789649, -0.64792851, -0.14435888],\n",
       "       [-0.5286097 , -0.71285299,  0.46088219]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.qr(np.random.randn(3,3))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# seaborn setup\n",
    "cmap = sns.color_palette('Set1')\n",
    "sns.set_palette(cmap)\n",
    "\n",
    "data = mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Model parameters\n",
    "m_dim = data.inputs.shape[1]\n",
    "p_dim = data.outputs.shape[1]\n",
    "\n",
    "#for...\n",
    "#  layer 0 input vector space\n",
    "#  layer 1:7 intermediate\n",
    "#  layer 8 final layer\n",
    "#convention: \"layers = 8\"\n",
    "\n",
    "layers = 8\n",
    "l_dim = [m_dim] + (layers-1)*[240] + [p_dim]\n",
    "stddev = 0.01\n",
    "b_init = 0.0\n",
    "alpha = 1\n",
    "\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholders\n",
    "x_in = tf.placeholder(tf.float32, shape=[batch_size, m_dim]) # Input\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, p_dim]) # Output\n",
    "epoch = tf.placeholder(tf.float32, shape=None) # training iteration\n",
    "\n",
    "noise_inj = .1/(1.+epoch/200.) # stddev\n",
    "\n",
    "# Initialize lists.\n",
    "b = (layers+1)*[None] \n",
    "W = (layers+1)*[None]\n",
    "x = (layers+1)*[None]\n",
    "\n",
    "L = (layers+1)*[None]\n",
    "L_inv = (layers+1)*[None]\n",
    "C = (layers+1)*[None]\n",
    "\n",
    "x_ = (layers+1)*[None]\n",
    "V = (layers+1)*[None]\n",
    "c = (layers+1)*[None]\n",
    "\n",
    "x_c = (layers+1)*[None]\n",
    "fx_c = (layers+1)*[None]\n",
    "\n",
    "train_op_inv = (layers+1)*[None]\n",
    "train_op = (layers+1)*[None]\n",
    "train_op_C = (layers+1)*[None]\n",
    "\n",
    "def f(ll, zz):\n",
    "    \"\"\"map from layer ll-1 to ll\"\"\"\n",
    "    return tf.nn.relu(tf.matmul(zz, W[ll]) + b[ll], name='f')\n",
    "\n",
    "def g(ll, zz):\n",
    "    \"\"\"map from layer ll to ll-1\"\"\"\n",
    "    return tf.nn.sigmoid(tf.matmul(zz, V[ll]) + c[ll], name='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward graph\n",
    "x[0] = x_in\n",
    "for l in range(1, layers+1):\n",
    "    with tf.name_scope('Layer_Forward'+str(l)):\n",
    "        b[l] = tf.Variable(tf.constant(b_init, shape=[1, l_dim[l]]), name='b')\n",
    "        W[l] = tf.Variable(tf.truncated_normal([l_dim[l-1], l_dim[l]], stddev=np.sqrt(6./(l_dim[l-1]+l_dim[l]))), name='W')\n",
    "        x[l] = f(l, x[l-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Top layer loss / top layer target\n",
    "L[-1] = tf.reduce_mean(-tf.reduce_sum(y*tf.log(tf.nn.softmax(x[-1])), reduction_indices=[1]))\n",
    "x_[-1] = x[-1] - alpha*tf.gradients(L[-1], [x[-1]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Feedback graph\n",
    "# for l in range(layers, 1, -1):\n",
    "#     with tf.name_scope('Layer_Feedback'+str(l)):\n",
    "#         c[l] = tf.Variable(tf.constant(b_init, shape=[1, l_dim[l-1]]), name='c')\n",
    "#         V[l] = tf.Variable(tf.truncated_normal([l_dim[l], l_dim[l-1]], stddev=np.sqrt(6./(l_dim[l-1]+l_dim[l]))), name='V')\n",
    "#         x_[l-1] = x[l-1] - g(l, x[l]) + g(l, x_[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTION 2 Specify targets exactly.\n",
    "for l in range(layers-1, 0, -1):\n",
    "    with tf.name_scope('Layer_targets'+str(l)):\n",
    "        x_[l] = tf.Variable(tf.random_normal([batch_size, l_dim[l]], stddev=np.sqrt(1/l_dim[l])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Corrupted targets\n",
    "for l in range(1, layers):\n",
    "    x_c[l] = tf.stop_gradient(tf.random_normal([1, l_dim[l]], mean=x[l], stddev=noise_inj), name='x_c')\n",
    "    fx_c[l+1] = tf.stop_gradient(f(l+1, x_c[l]), name='fx_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "for l in range(1, layers):\n",
    "    L[l] = tf.reduce_mean(0.5*(f(l, tf.stop_gradient(x[l-1])) - tf.stop_gradient(x_[l]))**2, name='L')\n",
    "beta = 1\n",
    "for l in range(1, layers):\n",
    "    C[l] = tf.reduce_mean(0.5*(x[l+1] - f(l+1, x_[l]))**2) + tf.reduce_mean(0.5*beta*(x[l] - x_[l])**2)\n",
    "\n",
    "# for i in range(2, layers+1):\n",
    "#     L_inv[i] = tf.reduce_mean(0.5*(g(i, fx_c[i]) - x_c[i-1])**2, name='L_inv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "opt = tf.train.AdamOptimizer(0.001)\n",
    "for l in range(1, layers+1):\n",
    "    train_op[l] = opt.minimize(L[l], var_list=[W[l], b[l]])\n",
    "for l in range(1, layers): # check\n",
    "    train_op_C[l] = opt.minimize(C[l], var_list=[x_[l]])\n",
    "#for l in range(2, layers+1):\n",
    "#    train_op_inv[l] = opt.minimize(L_inv[l], var_list=[V[l], c[l]])\n",
    "\n",
    "# Backprop. for reference\n",
    "train_bp = opt.minimize(L[-1], var_list=[i for i in W+b if i is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " <tensorflow.python.framework.ops.Operation at 0x123deed90>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x121253250>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x121df9f10>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x11cb5fd10>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x11d46aa10>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x12ef28190>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x12367ffd0>,\n",
       " None]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_op_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(x[-1]), 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up\n",
    "train_op = [i for i in train_op if i is not None]\n",
    "train_op_inv = [i for i in train_op_inv if i is not None]\n",
    "train_op_C = [i for i in train_op_C if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "for l in range(layers+1):\n",
    "    if L[l] is not None:\n",
    "        tf.scalar_summary('L'+str(l), L[l])\n",
    "    if L_inv[l] is not None:\n",
    "        tf.scalar_summary('L_inv'+str(l), L_inv[l])\n",
    "tf.scalar_summary('accuracy', accuracy)\n",
    "\n",
    "for var in tf.all_variables():\n",
    "    tf.histogram_summary(var.name, var)\n",
    "merged_summary_op = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.framework.ops.Operation at 0x12e049f90>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x12e1a9b10>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x12e30ad10>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x12e44c590>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x12e5ab910>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x12e71bf10>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x12e86ce90>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_op_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0000 loss: 2.3992 accuracy: 0.1440\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-f05fe818dd84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/tensorflow/python/training/summary_io.pyc\u001b[0m in \u001b[0;36madd_summary\u001b[0;34m(self, summary, global_step)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0msumm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0msumm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m       \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msumm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwall_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/google/protobuf/message.pyc\u001b[0m in \u001b[0;36mParseFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mMergeFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# The only reason _InternalParse would return early is if it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;31m# encountered an end-group tag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mInternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc\u001b[0m in \u001b[0;36mDecodeRepeatedField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    610\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0m_DecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Truncated message.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;31m# Read sub-message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m           \u001b[0;31m# The only reason _InternalParse would return early is if it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m           \u001b[0;31m# encountered an end-group tag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mInternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc\u001b[0m in \u001b[0;36mDecodeField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0m_DecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Truncated message.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m       \u001b[0;31m# Read sub-message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;31m# The only reason _InternalParse would return early is if it encountered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;31m# an end-group tag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mInternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc\u001b[0m in \u001b[0;36mDecodePackedField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m           \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m           \u001b[0;32mdel\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# Discard corrupt value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "run+=1\n",
    "\n",
    "summary_writer = tf.train.SummaryWriter('/tmp/targ-prop/'+str(run), sess.graph)\n",
    "\n",
    "for i in range(100000):\n",
    "    x_batch, y_batch = data.rand_batch(batch_size)\n",
    "    feed_dict={x_in: x_batch, y: y_batch, epoch: i}\n",
    "    #sess.run(train_op_inv, feed_dict=feed_dict)\n",
    "    sess.run(train_op_C, feed_dict=feed_dict)\n",
    "    sess.run(train_op, feed_dict=feed_dict)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        loss_val, summary_str, acc_val = sess.run([L[-1], merged_summary_op, accuracy], feed_dict=feed_dict)\n",
    "        summary_writer.add_summary(summary_str, i)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print \"iter:\", \"%04d\" % (i), \\\n",
    "              \"loss:\", \"{:.4f}\".format(loss_val), \\\n",
    "              \"accuracy:\", \"{:.4f}\".format(acc_val)\n",
    "\n",
    "print \"finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "# # Global loss\n",
    "# #L_g = tf.reduce_mean(0.5*(x[-1] - y)**2, name=\"global_loss\")\n",
    "# with tf.variable_scope('global_loss'):\n",
    "#     L_g = tf.reduce_mean(-tf.reduce_sum(y*tf.log(tf.nn.softmax(x[-1])), reduction_indices=[1]))\n",
    "\n",
    "# # Top-layer targets\n",
    "# L_grads = tf.gradients(L_g, [x[-1]])\n",
    "\n",
    "# x_tar[-1] = x[-1] - alpha*L_grads[0]\n",
    "# #x_tar[-2] = x[-2] - alpha*L_grads[1]\n",
    "\n",
    "# # Target graph\n",
    "# for l in range(layers,0,-1): # from M to 2\n",
    "#     with tf.name_scope('layer_target'+str(l)) as scope:\n",
    "#         if x_tar[l] is None:\n",
    "#             x_tar[l] = x[l] + gx_tar[l+1] - gx[l+1] # gx[l+1] must be defined of course...\n",
    "#         if l > 1:\n",
    "#             c[l] = tf.Variable(tf.constant(b_init, shape=[1, l_dim[l-1]]), name='c')\n",
    "#             V[l] = tf.Variable(tf.truncated_normal([l_dim[l], l_dim[l-1]], stddev=np.sqrt(6./(l_dim[l-1]+l_dim[l]))), name='V')\n",
    "#             gx[l] = tf.nn.sigmoid(tf.add(tf.matmul(x[l], V[l]), c[l]), name='g_x')\n",
    "\n",
    "#             gx_tar[l] = tf.nn.sigmoid(tf.add(tf.matmul(x_tar[l], V[l]), c[l]), name='g_x_tar')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Optimizers\n",
    "# opt = tf.train.AdamOptimizer(0.001)\n",
    "\n",
    "# train_op_inv = (layers+1)*[None]\n",
    "# train_op = (layers+1)*[None]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fx_ = (layers+1)*[None] # f(x + eps)\n",
    "# gx_ = (layers+1)*[None] # g(f(x + eps))\n",
    "\n",
    "# for l in range(2, layers+1):\n",
    "#     with tf.name_scope('L_inv_layer'+str(l)) as scope:\n",
    "#         fx_[l] = tf.nn.sigmoid(tf.matmul(x[l-1], W[l]) + b[l] + tf.random_normal(b[l].get_shape(), stddev=noise_inj))\n",
    "#         gx_[l] = tf.nn.sigmoid(tf.matmul(fx_[l], V[l]) + c[l])\n",
    "#         with tf.name_scope('L_inv'):\n",
    "#             L_inv[l] = tf.reduce_mean(0.5*(gx_[l] - (x[l-1] + tf.random_normal(c[l].get_shape(), stddev=noise_inj)))**2,\n",
    "#                                       name='L_inv')\n",
    "#         train_op_inv[l] = opt.minimize(L_inv[l], var_list=[V[l], c[l]])\n",
    "\n",
    "# for l in range(1, layers+1):\n",
    "#     with tf.name_scope('L_layer'+str(l)) as scope:\n",
    "#         with tf.name_scope('L'):\n",
    "#             L[l] = tf.reduce_mean(0.5*(x[l] - x_tar[l])**2, name=\"L\")\n",
    "#         train_op[l] = opt.minimize(L[l], var_list=[W[l], b[l]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
